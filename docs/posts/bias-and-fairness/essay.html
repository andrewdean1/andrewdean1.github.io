<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andrew Dean">
<meta name="dcterms.date" content="2025-03-26">
<meta name="description" content="Disccusses, considers, and critiques the the methods used to ensure fairness in ML algorithms.">

<title>Limits of the Quantitative Approach to Bias and Fairness – Andrew Dean’s Machine Learning Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6685f57f7611d95a701d58b4cc6878c0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andrew Dean’s Machine Learning Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/andrewdean1"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#understanding-fairness" id="toc-understanding-fairness" class="nav-link" data-scroll-target="#understanding-fairness">Understanding Fairness</a></li>
  <li><a href="#quantitative-methods" id="toc-quantitative-methods" class="nav-link" data-scroll-target="#quantitative-methods">Quantitative Methods</a></li>
  <li><a href="#narayanans-view" id="toc-narayanans-view" class="nav-link" data-scroll-target="#narayanans-view">Narayanan’s View</a></li>
  <li><a href="#the-quantitative-method-falling-short" id="toc-the-quantitative-method-falling-short" class="nav-link" data-scroll-target="#the-quantitative-method-falling-short">The Quantitative Method: Falling Short</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Limits of the Quantitative Approach to Bias and Fairness</h1>
</div>

<div>
  <div class="description">
    Disccusses, considers, and critiques the the methods used to ensure fairness in ML algorithms.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Andrew Dean </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 26, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Data now fuels many aspects of daily life. Digital technologies continually record our activities using structured formats such as databases and JSON files from social media. Rapid advances in data processing mean that large datasets are easily and quickly retrieved via APIs for analysis. Machine learning systems use this information to make decisions and recommendations, often without users’ explicit awareness. For industries, governments, and academic researchers, these models are indispensable - but they have also exhibited systemic biases. As algorithmic decision-making expanded into consequential domains, critics have identified biases against specific demographic groups. Notable examples that we have discussed include predictive policing algorithms and criminal recidivism tools that were demonstrated to exhibit significant bias against racial minorities. Because of this, it is crucial to employ metrics that assess algorithmic fairness. Today, various fairness verification frameworks are widely used, employing various quantitative methodologies, but this does not mean algorithms are thus definitively fair. Before we get into that, let’s discuss what fairness truly means in the machine learning realm.</p>
</section>
<section id="understanding-fairness" class="level2">
<h2 class="anchored" data-anchor-id="understanding-fairness">Understanding Fairness</h2>
<p>Three primary quantitative fairness definitions exist. Error rate parity ensures all groups experience identical false negative and false positive rates - meaning algorithmic mistakes occur with equal frequency regardless of whether an individual belongs to Group A or Group B. Acceptance rate parity equalizes acceptance rates across all groups, ensuring algorithmic outcomes remain independent of group membership. Sufficiency requires that the probability of experiencing a positive outcome following a positive prediction remains consistent across all subgroups while similarly ensuring the probability of experiencing a negative outcome following a negative prediction remains uniform across subgroups. Another key notion, demographic parity, mandates equal selection rates across groups, aligning with the moral perspective of distributive justice by aiming to prevent systemic disadvantage. However, as Barocas, Hardt, and Narayanan (<span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>) note, this approach can overlook differences in qualification rates, raising questions about its applicability in ensuring true fairness.</p>
<p>From a moral perspective, three viewpoints frame fairness considerations: narrow, middle, and broad. The narrow view maintains that individuals similar in task-relevant aspects deserve similar treatment, comparing all people as individuals rather than as group members. The middle view says that decision-makers must avoid perpetuating injustice by treating apparently dissimilar individuals similarly when their differences stem from problematic origins. The broad equality view aspires for individuals with comparable abilities and ambitions to achieve similar successes despite inevitable inequalities. This perspective transcends decision-making fairness to address the fundamental design of societal institutions, aiming to prevent unjust disparities from emerging initially (<span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>).</p>
<p>A real-world example illustrating the challenges of quantitative fairness is the use of the COMPAS algorithm in the U.S. judicial system to predict recidivism. A study by ProPublica found that Black defendants were disproportionately labeled as higher risk compared to white defendants, despite similar reoffending rates (<span class="citation" data-cites="angwinFairnessMachineLearning2016">Angwin et al. (<a href="#ref-angwinFairnessMachineLearning2016" role="doc-biblioref">2016</a>)</span>). This case highlights the difficulties in achieving error rate parity, as false positive and false negative rates were not equal across racial groups. From a moral standpoint, this aligns with the middle fairness perspective, which emphasizes the importance of addressing systemic biases that lead to unjust outcomes (<span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>).</p>
</section>
<section id="quantitative-methods" class="level2">
<h2 class="anchored" data-anchor-id="quantitative-methods">Quantitative Methods</h2>
<p>​An illustrative example of employing both quantitative and moral frameworks to critique algorithmic bias is found in the study “Algorithmic Bias? An Empirical Study into Apparent Gender-Based Discrimination in Displaying STEM Career Ads” by Lambrecht and Tucker (<span class="citation" data-cites="lambrechtAlgorithmicBiasEmpirical2019">Lambrecht and Tucker (<a href="#ref-lambrechtAlgorithmicBiasEmpirical2019" role="doc-biblioref">2019</a>)</span>). This research investigates whether online advertising algorithms display STEM job advertisements differently based on gender. The authors conducted a field experiment by creating ads for STEM careers and observed their delivery across users. Their findings revealed that, even when controlling for factors like user behavior and advertiser intent, women were less likely to be shown these ads compared to men. The study suggests that this disparity arises not from explicit gender bias in the algorithms themselves but from underlying economic factors that lead to unintended, uneven outcomes. For instance, if women are less likely to click on STEM ads, the algorithm may optimize ad delivery towards men to maximize engagement, inadvertently perpetuating gender imbalances in STEM fields. This scenario demonstrates a failure to uphold the principle of demographic parity, where the likelihood of viewing a STEM career advertisement should be independent of gender. From a broader ethical standpoint, the study highlights the responsibility of platforms to ensure that their algorithms do not reinforce societal stereotypes or existing disparities. By critically analyzing and addressing these biases, the research underscores the importance of integrating both quantitative assessments and moral considerations to foster fairness in algorithmic decision-making.​</p>
</section>
<section id="narayanans-view" class="level2">
<h2 class="anchored" data-anchor-id="narayanans-view">Narayanan’s View</h2>
<p>Quantitative definitions of fairness alone are insufficient to exonerate an algorithm, argues Arvind Narayanan, a computer scientist and professor at Princeton University. In his October 11th, 2022 talk, titled <em>“The Limits of the Quantitative Approach to Discrimination,”</em> Narayanan presents a critical perspective on the overreliance on classical numerical fairness metrics. His key assertion highlights this: “Currently quantitative methods are primarily used to justify the status quo. I would argue that they do more harm than good” (<span class="citation" data-cites="narayananLimitsQuantitativeApproach2022">Narayanan (<a href="#ref-narayananLimitsQuantitativeApproach2022" role="doc-biblioref">2022</a>)</span>).</p>
<p>He opens his speech with a well known quote: “all models are wrong, but some models are useful” (<span class="citation" data-cites="narayananLimitsQuantitativeApproach2022">Narayanan (<a href="#ref-narayananLimitsQuantitativeApproach2022" role="doc-biblioref">2022</a>)</span>), emphasizing that no machine learning model is perfectly accurate. The very process of simplifying complex realities into data-friendly trends inevitably introduces bias. By relying on these generalizations, models unintentionally reinforce the existing state of the world - a state already riddled with inequality and discrimination. Narayanan points out that data is far from neutral, stating, “data aren’t inert and objective. They are political, and produced towards certain ends” (<span class="citation" data-cites="narayananLimitsQuantitativeApproach2022">Narayanan (<a href="#ref-narayananLimitsQuantitativeApproach2022" role="doc-biblioref">2022</a>)</span>). Since data collection serves specific purposes, bias is inherently woven into the dataset from the start.</p>
<p>This idea is further elaborated in <em>Fairness and Machine Learning: Limitations and Opportunities,</em> co-authored by Narayanan, Barocas, and Hardt. The authors explain how the world’s complexities are distilled into rows, columns, and numerical values — an inherently flawed process. They challenge the notion of data as an objective snapshot of reality, arguing that “the term measurement is misleading, evoking an image of a dispassionate scientist recording what she observes, yet…it requires subjective human decisions” (<span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>).</p>
<p>While people often believe data speaks for itself, Narayanan offers a more clear cut view: data is less an impartial truth and more a reflection of the systemic biases and inequalities that shape society. To counteract this, he advocates for a shift in focus: “we should be spending most of our time on curating and interrogating datasets before ever searching for statistical significance or fitting a model … it is important to look behind the facade of numbers to understand the hidden assumptions and politics of datasets” (<span class="citation" data-cites="narayananLimitsQuantitativeApproach2022">Narayanan (<a href="#ref-narayananLimitsQuantitativeApproach2022" role="doc-biblioref">2022</a>)</span>). This approach essentially reframes the role of data analysis, urging researchers to prioritize understanding the dataset’s origins and embedded biases rather than rushing to derive conclusions from potentially flawed numbers.</p>
</section>
<section id="the-quantitative-method-falling-short" class="level2">
<h2 class="anchored" data-anchor-id="the-quantitative-method-falling-short">The Quantitative Method: Falling Short</h2>
<p>Arvind Narayanan’s critique underscores the limitations of relying solely on quantitative methods to assess algorithmic fairness. In Bokányi and Hannák’s study, “Ride-share matching algorithms generate income inequality” (<span class="citation" data-cites="bokanyiRideshareMatchingAlgorithms2021">Bokányi and Hannák (<a href="#ref-bokanyiRideshareMatchingAlgorithms2021" role="doc-biblioref">2021</a>)</span>), the authors use a detailed computational model to illustrate how small changes in parameters - such as taxi density, demand-to-supply ratios, spatial distributions of trips, and driver idling strategies — can lead to considerable and unpredictable income disparities among drivers with identical work efforts. While the study rigorously exposes how algorithm design choices can trigger significant wage gaps through feedback loops, relying exclusively on these quantitative findings can mislead platform designers. If designers assumed that optimizing these numerical metrics fully defines their responsibilities, they might neglect broader ethical concerns that go far beyond optimizing these said unequal measurements. For example, if drivers still suspect that some inequality is present, if the platform designers think their algorithm is now perfect because they “solved” its prior flaws, they may disregard any further questioning on their platoform being fair. This narrow focus could prompt decisions that, for example, prioritize short-term efficiency and income equality while overlooking long-term structural inequities, ultimately reinforcing systemic biases. An example of this could be a platform solely optimizing its algorithm to balance daily driver incomes by assigning more rides to those with lower earnings; while this might yield fairer distributions on paper in the short run, it could inadvertently relegate drivers in underserved areas to persistently low-earning regions, thereby deepening geographic income disparities and perpetuating long-term structural inequities. In effect, by omitting the perspective that includes ethical and socio-economic implications, platform designers risk making poor decisions that perpetuate vulnerabilities among drivers. Thus, while the study is invaluable in quantifying disparities, its omission of systemic and ethical dimensions could lead to harmful, one-dimensional interventions if taken as a comprehensive guideline for algorithmic responsibility.</p>
<p>This study exemplifies what D’Ignazio and Klein (<span class="citation" data-cites="dignazioDataFeminism2023">D’Ignazio and Klein (<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">2023</a>)</span>) term “Big Dick Data” in Data Feminism. They define this concept as big data projects driven by patriarchal, controlling ambitions of totalizing control through data collection and analysis. These projects are particularly harmful because they disregard context and overstate their technical and scientific authority. Data Feminism emphasizes the necessity of interrogating the the platforms under which data is gathered, an essential step that Ali et al.&nbsp;blatantly neglected.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>To tie it back to Narayanan’s speech, he opens it up with a statement that should not be taken lightly: “I hope that this talk goes some way towards busting the myth that numbers don’t lie” (<span class="citation" data-cites="narayananLimitsQuantitativeApproach2022">Narayanan (<a href="#ref-narayananLimitsQuantitativeApproach2022" role="doc-biblioref">2022</a>)</span>). By the end, it’s clear that numbers, while often treated as objective truth, are shaped by the biases baked into the data they’re drawn from. This challenges the common belief that many, including myself, have in data as a driving force of truth. Through exploring these studies, it becomes evident that datasets are never fully neutral or detached from the world’s inequalities, and should thus all be taken from a critical perspective. As seen in the studies I have discussed, researchers can manipulate quantitative methods to validate their desired outcomes and frame the results in a way that is favorable to their argument.</p>
<p>Narayanan’s argument pushes even further, claiming that quantitative methods often do more harm than good, reinforcing systemic biases under the notion of objectivity. While this criticism holds weight, I believe the solution isn’t to abandon quantitative methods altogether but to recognize their limitations and use them more thoughtfully. Quantitative metrics can still be powerful tools to uncover injustice if used responsibly. The key lies in avoiding reliance on any single definition of fairness. Since different definitions can yield conflicting conclusions, multiple perspectives must be considered to paint a fuller, more honest picture of algorithmic behavior. Moreover, numbers alone are never enough. Ethical frameworks, including the narrow, middle, and broad views of fairness, must guide how we interpret and apply these metrics. Only by blending quantitative analysis with moral reasoning can we hope to uncover and challenge the hidden biases within algorithmic systems.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-angwinFairnessMachineLearning2016" class="csl-entry" role="listitem">
Angwin, Julia, ProPublica Larson, Jeff Mattu, and Lauren Kirchner. 2016. <span>“Machine Bias.”</span> <em>ProPublica</em>.
</div>
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. <span>MIT Press</span>.
</div>
<div id="ref-bokanyiRideshareMatchingAlgorithms2021" class="csl-entry" role="listitem">
Bokányi, Eszter, and Anikó Hannák. 2021. <span>“Ride-Share Matching Algorithms Generate Income Inequality.”</span> <em>Scientific Reports</em> 11 (1): 8537.
</div>
<div id="ref-dignazioDataFeminism2023" class="csl-entry" role="listitem">
D’Ignazio, Catherine, and Lauren F Klein. 2023. <em>Data Feminism</em>. <span>MIT Press</span>.
</div>
<div id="ref-lambrechtAlgorithmicBiasEmpirical2019" class="csl-entry" role="listitem">
Lambrecht, Anja, and Catherine Tucker. 2019. <span>“Algorithmic Bias? An Empirical Study into Apparent Gender-Based Discrimination in Displaying STEM Career Ads.”</span> <em>Management Science</em> 65 (7): 2966–81.
</div>
<div id="ref-narayananLimitsQuantitativeApproach2022" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>